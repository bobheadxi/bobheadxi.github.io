---
title: ":boat: Domain-Specific Search Engine"
layout: post
tag:
- python
- django
- scrapy
- solr
- docker
- javascript
- react 
- launch-pad
image: /assets/images/projects/sleuth-1.png
headerImage: false
hidden: true # don't count this post in blog pagination
description: "<i>Sleuth</i> - domain-specific broad crawling and a feature-rich, well-designed, and thoroughly tested RESTful API"
author: robert
star: false
externalLink: false
badges:
- <img src="https://coveralls.io/repos/github/ubclaunchpad/sleuth/badge.svg?branch=master" alt="Coverage Status" />
---

<p align="center">
    <img src="/assets/images/projects/sleuth-1.png" />
</p>

<p align="center">
    <a href="https://github.com/ubclaunchpad/sleuth">
        <img src="https://img.shields.io/badge/GitHub-sleuth-blue.svg?style=for-the-badge" alt="Server Repository"/>
    </a>
    <a href="https://github.com/ubclaunchpad/sleuth-frontend">
        <img src="https://img.shields.io/badge/GitHub-sleuth--frontend-blue.svg?style=for-the-badge" alt="Website Repository"/>
    </a>
</p>

<p align="center">
    <img src="https://coveralls.io/repos/github/ubclaunchpad/sleuth/badge.svg?branch=master"
        alt="Coverage Status" />
    <img src="https://img.shields.io/github/languages/top/ubclaunchpad/sleuth.svg?colorB=00A9FD"
        alt="Server language" />
    <img src="https://img.shields.io/github/languages/top/ubclaunchpad/sleuth-frontend.svg?colorB=FDB000"
        alt="Frontend language" />
    <img src="https://img.shields.io/github/contributors/ubclaunchpad/sleuth.svg" />
</p>

Ever wanted to find something specific about the University of British Columbia - such as your course site - only to find yourself wading through a hundred irrelevant Google results? Sleuth is a service that allows anyone to search up UBC-relevant content gathered by our own web crawlers and indexed by our own database built on Solr.

Built by a tiny team of 2, the Sleuth project features two major components - the Sleuth backend and server, and the Sleuth frontend website, both of which can be easily deployed through Docker using a simple `docker-compose up` command. The backend features:

* **comprehensive and well-documented endpoints** built on Django that expose the Sleuth search service through RESTful APIs and serve relevant errors and status codes thanks to effective exception handling within the codebase
* a **robust and modular architecture** featuring custom internal query-building modules to simplify tweaking our search parameters and weights and abstracted database component built on Apache Solr
* **domain-specific broad crawlers** designed to handle all sorts of web pages and content, parsing them in relevant formats through our efficient data pipeline featuring automated entry queuing (read more in my [blog post](https://medium.com/ubc-launch-pad-software-engineering-blog/crawling-the-web-for-a-search-engine-a7988ee2e6e9)!)
* **relevant results** using webpage links and key words determined by natural language processing libraries to connect related results and served by the Sleuth APIs
* **thoroughly tested** code, with over 90% coverage

The React-based Sleuth frontend features:

* **innovative, sprawling, network-based results view** to allow users to determine what results might be most relevant to them at a glance, though Sleuth also provides a more traditional list-based view for those inclined
* **close integration** with the Sleuth backend to display summaries of the various webpage types stored by the Sleuth crawler

More details can be found in the two Sleuth repositories!

<p align="center">
    <img src="/assets/images/projects/sleuth-pipeline.png" />
</p>

<p align="center">
    Sleuth's crawler pipeline, as described in <a href="https://medium.com/ubc-launch-pad-software-engineering-blog/crawling-the-web-for-a-search-engine-a7988ee2e6e9">this post</a>
</p>

<br />
